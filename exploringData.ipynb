{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data wrangling on OpenStreetMaps data\n",
    "-------------\n",
    "In this project -- which is part of the Udacity Data Analysis Nanodegree -- I will apply some data munging techniques, such as assessing the quality of the data for validity, accuracy, completeness, consistency and uniformity, to clean an specific area from OpenStreetMap data. After it, in order to try database manipulation in Python, I will load the cleaned data to a MongoDB collection (installed locally in my machine) and apply some simple statistics on it.  \n",
    "\n",
    "*This Jupyter notebook was iterated over the whole data wrangling process. This final version was also cleaned to offer a project overview in a thorough but also succint way. If you are curious about how it all was build, take a look at the different versions on the Git repository.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choosing an OpenStreetMap region: Missões!\n",
    "My region of interest in this project is Santo Ângelo, a countryside small city in the southest estate of Brazil which were my birthplace. However, since there's few data for this city and I'm supposed to deal with databases larger than 50MB, for this project, I will consider all the neighboring cities, which in turn constitute the \"Missões\" region [1] and represent an important chapter in the South American history, since the first settlements were founded during the Spanish colonial missions [2].  \n",
    "\n",
    "<img src=\"https://lh3.googleusercontent.com/oGx4LKGq3sWb7Xkf4fsGBnxankZenzudDpU1I7nKIZxH7nT8OVV5COhb8XgchKHpk4GoveTM3B_dHU3tPtUTbo3SrjR19n45kxli6GPnGgHFM3O6qe68wBQVnQKePtnIBa_HX473yWggGuE8sTZaoEQOX4hHehMyZnp2ldOxji79vN6lQSMuDziFKz2NK-E9TASvEDnPJtVaxnuGHzWrjMfjd3bjF32PkZWKqmQjOouU1eCSOW2KM5gb53ntQYvAZT7K6TbaPP_rhwtrJGiX9BAoAtUMo6jA2CpfygbK9RMsstGgiF2IZRxVRwtOeCYLCIaJp6O6Bxx_1QeVIKZiPl4IB2xQWHJU9DHrFI-BGTEatLdyNRW-w9vkn_-erwalDNAHX-GzzxNKAXg6ezI7dUxe-jB2s1as4eIPi3dZibmEuzfQ3wSmmMm3irptNMQGwGvsp67Q92HqZFrf5K9gm9Z3OywTy9X2IRSnfkzVtJsNmU1aH8IAyAPbPq3lJST2bueFKnt6yFxbCFz0Pv1w15NxaQ6ZT24iRhWkbutkLRKOn5s6XLXXucKAR-AwB-ehIKhusiQ5elJK2Hl6EeseEawH8_8b5NCKQ4eiIhDi76BpqcQfVJCcltEQXNzBEzPBrcdYsiDG2Qm0MSWvQXbuC6Fbno7gURB3RXMQhv1l8-eS4np29VrB8Ehi=s1043-no\" alt=\"missoes\" width=\"600\"/>\n",
    "\n",
    "Although today there are 46 municipalities composing this region, in the early eighteenth century there were only 7 villages, nowadays known in Portuguese as the \"Sete Povos das Missões\".  \n",
    "\n",
    "For this project, though, I have the following objectives:  \n",
    "i. Collect, audit and clean data from OpenStreetMap related to this region;  \n",
    "ii. Get insights from data regarding this region historical value, as well as its current touristic status."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------\n",
    "## Some basic statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.cElementTree as ET\n",
    "from collections import defaultdict\n",
    "import pprint\n",
    "import re\n",
    "import codecs\n",
    "import json\n",
    "\n",
    "# Dataset file name:\n",
    "FILENAME = 'Missoes.osm'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------\n",
    "## Getting and reading the data:\n",
    "The data was obtained from OpenStreetMap (OSM) selecting a specific region in the southern part of Brazil, as shown below:  \n",
    "\n",
    "<img src=\"OSM_missoes_region.png\" alt=\"missoes\" width=\"600\"/>\n",
    "\n",
    "After downloading the data, the first step I should do if I did not know the data model would be a simple \"less\" shell command to figure out what kind of data were in it. Since OpenStreetMaps provides us with a data model, which in turn tells us how the information is organized inside the database, we get to know that the information we are interested in are in keys called 'tag'. Just to check how many of them we will have to process on this data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bounds': 1,\n",
      " 'member': 15589,\n",
      " 'meta': 1,\n",
      " 'nd': 444388,\n",
      " 'node': 380322,\n",
      " 'note': 1,\n",
      " 'osm': 1,\n",
      " 'relation': 949,\n",
      " 'tag': 93511,\n",
      " 'way': 45320}\n"
     ]
    }
   ],
   "source": [
    "#%% Getting acquainted to the dataset\n",
    "def count_tags(filename):\n",
    "    tags = {}\n",
    "    for event, element in ET.iterparse(filename):\n",
    "        if element.tag not in tags:\n",
    "            tags[element.tag] = 1\n",
    "        else: \n",
    "            tags[element.tag] += 1\n",
    "    return tags\n",
    "\n",
    "tags = count_tags(FILENAME)\n",
    "pprint.pprint(tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 93.511 tags we'll be dealing with in the next steps. We can move forward to the next step: starting to audit our data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------\n",
    "## Auditing data:  \n",
    "The auditing questions comes when we start exploring the data or, if it's the case we have a prior knowledge of the problem, we already have in mind some issues to investigate. Considering there are available on Internet some similar analysis on OpenStreetMap data [3,4]; and also considering my previous knowledge about this region, I intend to audit the following issues:  \n",
    "- Are the cities names correct?\n",
    "- Are the street names correct?\n",
    "- Are there abbreviations?\n",
    "- Are the postal codes consistent?  \n",
    "\n",
    "It must be said that here the data are being first explored iteratively. Besides it is recommended to have one script for each field that is being audited, the whole process will be done through this Jupyter notebook in order to give an overview of the cleaning process. At the end, the code will be transferred to a standalone Python script (.py), in order to facilitate its automation when converting, cleaning and exporting data to a MongoDB collection, for example. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Are the cities names correct?\n",
    "In order to answer this question, I need first to know where this information is in the OpenStreetMaps (OSM) data model, which can be found in [5]. Consulting the documentation we get to know we are looking for the *addr:city* key. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 18 distinct cities in the dataset.\n",
      "['santa rosa', 'condor', 'ijuí', 'panambi', 'santo ângelo', 'três de maio', 'panambi - rs', 'santo cristo', 'eugênio de castro', 'santo augusto', 'santo angelo', 'cruz alta', 'vila sírio', 'cerro largo', 'são josé do mauá', 'são miguel das missões', 'horizontina', 'ijui']\n"
     ]
    }
   ],
   "source": [
    "#%% Finding the cities in the dataset\n",
    "def list_cities(filename):\n",
    "    cities = []\n",
    "    for _, elem in ET.iterparse(filename):\n",
    "        if elem.tag == 'tag':\n",
    "            k = elem.attrib['k']\n",
    "            v = elem.attrib['v'].lower()  #Lowering the uppercase text\n",
    "            if k == 'addr:city':\n",
    "                if v not in cities:\n",
    "                    cities.append(v)\n",
    "    print('There are {0} distinct cities in the dataset.'.format(len(cities)))\n",
    "    return cities\n",
    "\n",
    "cities = list_cities(FILENAME)\n",
    "print(cities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (1) Same cities are recorded with distinct names due to hyphenization or accentuation\n",
    "Even though I choose to use lowercase text, there are cities whose names are written with accentuation or hyphenized with the State abbreviation. A possible way to fix it is mapping the correct name to each case:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Cleaning the cities names:\n",
    "expected_cities = ['santa rosa', 'condor', 'ijuí', 'panambi', 'santo ângelo', 'três de maio',\n",
    "            'santo cristo', 'eugênio de castro', 'santo augusto', 'cruz alta', 'vila sírio', \n",
    "            'cerro largo', 'são josé do mauá', 'são miguel das missões', 'horizontina']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def audit_cities(expected_cities, filename):\n",
    "    weird = []\n",
    "    for _, elem in ET.iterparse(filename):\n",
    "        if elem.tag == 'tag':\n",
    "            k = elem.attrib['k']\n",
    "            v = elem.attrib['v'].lower()  #Lowering the uppercase text\n",
    "            if k == 'addr:city':\n",
    "                if v not in expected_cities:\n",
    "                    weird.append(v)\n",
    "    weird = set(weird)\n",
    "    print('There are {0} not expected cities in the dataset.'.format(len(weird)))\n",
    "    return weird"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 3 not expected cities in the dataset.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'ijui', 'panambi - rs', 'santo angelo'}"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audit_cities(expected_cities, FILENAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Are the street names correct? Are there any abbreviation?\n",
    "We will now iterate over all the registers to find wrong street names or abbreviations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "expected = [\"Rua\", \"Avenida\", \"Praça\", \"Via\", \"Estrada\", \"Travessa\", \"Linha\", \"Alameda\", \"Largo\", \"Parque\", \"Rodovia\"]\n",
    "\n",
    "### IMPORTANT: Brazilian street types are in the beginning of the phrase:\n",
    "street_type_re = re.compile(r'^\\b\\S+\\.?', re.IGNORECASE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def audit_street_type(street_types, street_name):\n",
    "    m = street_type_re.search(street_name)\n",
    "    if m:\n",
    "        street_type = m.group()\n",
    "        if street_type not in expected:\n",
    "            street_types[street_type].add(street_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_street_name(elem):\n",
    "    return (elem.attrib['k'] == \"addr:street\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def audit(osmfile):\n",
    "    osm_file = open(osmfile, \"r\")\n",
    "    street_types = defaultdict(set)\n",
    "    for event, elem in ET.iterparse(osm_file, events=(\"start\",)):\n",
    "        if elem.tag == \"node\" or elem.tag == \"way\":\n",
    "            for tag in elem.iter(\"tag\"):\n",
    "                if is_street_name(tag):\n",
    "                    audit_street_type(street_types, tag.attrib['v'])\n",
    "\n",
    "    return street_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'14': {'14 de Julho'},\n",
      " '15': {'15 de Novembro'},\n",
      " 'Av.': {'Av. Gustav Kuhlmann', 'Av. Santa Bárbara'},\n",
      " 'BR': {'BR 285'},\n",
      " 'BR-285': {'BR-285'},\n",
      " 'BR-392': {'BR-392'},\n",
      " 'BR158': {'BR158'},\n",
      " 'Dom': {'Dom Pedro II'},\n",
      " 'ERS-342': {'ERS-342'},\n",
      " 'Getúlio': {'Getúlio Vargas'},\n",
      " 'Padre': {'Padre Afonso Rodrigues'},\n",
      " 'Paulo': {'Paulo Klemann'},\n",
      " 'RS': {'RS 218'},\n",
      " 'Santa': {'Santa Lucia'}}\n"
     ]
    }
   ],
   "source": [
    "def test_streets():\n",
    "    st_types = audit(FILENAME)\n",
    "    pprint.pprint(dict(st_types))\n",
    "    \n",
    "test_streets()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the 'weirdos' found above, we could write some mapping dictionaries and functions to clean the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Are the postal codes consistent?\n",
    "The Brazilian postal codes are known as CEP and must contain 8 digits in the following format '00000-000'. Furthermore, in the Missões region the CEP numbers always start with the digit 9. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "cep = re.compile(r\"[0-9]{5}-[0-9]{3}\") #Alternative: cep = re.compile('d{5}-d{3}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_cep(elem):\n",
    "    return (elem.attrib['k'] == \"addr:postcode\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def audit_cep(filename):\n",
    "    osm_file = open(filename, \"r\")\n",
    "    bad_cep = []\n",
    "    for event, elem in ET.iterparse(osm_file, events=(\"start\",)):\n",
    "        if elem.tag == \"node\" or elem.tag == \"way\":\n",
    "            for tag in elem.iter(\"tag\"):\n",
    "                if is_cep(tag):\n",
    "                    v = tag.attrib['v']\n",
    "                    if cep.match(v):\n",
    "                        pass\n",
    "                    else:\n",
    "                        bad_cep.append(v)\n",
    "    return bad_cep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['98910000']"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audit_cep(FILENAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the questions and the attemptives to answer them, we could create some mapping dictionaries and updating functions to clean the data. They are suppresed from this notebook but can be found in the *final_project_code.py* script."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------\n",
    "## Cleaning, shaping and exporting data\n",
    "After auditing and deciding which data must be cleaned, it's time to shape the data into the model that will be exported to a MongoDB collection.  \n",
    "\n",
    "The output should be a list of dictionaries that look like this:\n",
    ">*{  \n",
    "\"id\": \"2406124091\",  \n",
    "\"type: \"node\",  \n",
    "\"visible\":\"true\",  \n",
    "\"created\": {  \n",
    "          \"version\":\"2\",  \n",
    "          \"changeset\":\"17206049\",  \n",
    "          \"timestamp\":\"2013-08-03T16:43:42Z\",  \n",
    "          \"user\":\"linuxUser16\",  \n",
    "          \"uid\":\"1219059\"  \n",
    "        },  \n",
    "\"pos\": [41.9757030, -87.6921867],  \n",
    "\"address\": {  \n",
    "          \"housenumber\": \"5157\",  \n",
    "          \"postcode\": \"60625\",  \n",
    "          \"street\": \"North Lincoln Ave\"  \n",
    "        },  \n",
    "\"amenity\": \"restaurant\",  \n",
    "\"cuisine\": \"mexican\",  \n",
    "\"name\": \"La Cabana De Don Luis\",  \n",
    "\"phone\": \"1 (773)-271-5176\"  \n",
    "}*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After concluding the audit and cleaning process, all the functions were concatenated on a python script in order to export the final data to a json file (Missoes.osm.json), which then can be loaded to a MongoDB collection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------\n",
    "## Data exploration through MongoDB API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loading MongoDB libraries\n",
    "from pymongo import MongoClient\n",
    "import pprint\n",
    "## Loading Pandas for data analysis\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Acessando o banco de dados\n",
    "client = MongoClient('mongodb://localhost:27017/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tbnsilveira/anaconda3/envs/analytics3/lib/python3.6/site-packages/ipykernel/__main__.py:2: DeprecationWarning: database_names is deprecated. Use list_database_names instead.\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['admin', 'config', 'examples', 'local', 'udacity']"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Lendo os bancos de dados disponíveis:\n",
    "client.database_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tbnsilveira/anaconda3/envs/analytics3/lib/python3.6/site-packages/ipykernel/__main__.py:2: DeprecationWarning: collection_names is deprecated. Use list_collection_names instead.\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['osm']"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Lendo as coleções disponíveis:\n",
    "client.udacity.collection_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating an alias:\n",
    "db = client.udacity.osm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_id': ObjectId('5badbef1ef1c25cdb2e4eefb'),\n",
      " 'created': {'changeset': '23072634',\n",
      "             'timestamp': '2014-06-21T23:33:37Z',\n",
      "             'uid': '1714450',\n",
      "             'user': 'Papibaquígrafo',\n",
      "             'version': '2'},\n",
      " 'id': '282841128',\n",
      " 'pos': [-28.1743824, -54.8258869],\n",
      " 'type': 'node'}\n"
     ]
    }
   ],
   "source": [
    "## Checking the first instance:\n",
    "firstInstance = db.find_one()\n",
    "pprint.pprint(firstInstance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the data is available, now it's time to explore it in the way to find the answers for some questions:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Database overview\n",
    "We have collected a small portion of OSM. Knowing the data is written in \"nodes\" and \"ways\", it would be important to know quantitavely the amount of data available, which in turn may determine the confidence of any conclusion taken from this data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_information():\n",
    "    nDocs = db.find().count()\n",
    "    nNodes = db.find({'type':'node'}).count()\n",
    "    nWays = db.find({'type':'way'}).count()\n",
    "    nUsers = len(db.distinct(\"created.user\"))\n",
    "    print('Database overview:\\nDocuments: {0}\\nNodes: {1}\\nWays: {2}\\nUsers: {3}'.format(nDocs, nNodes, nWays, nUsers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tbnsilveira/anaconda3/envs/analytics3/lib/python3.6/site-packages/ipykernel/__main__.py:2: DeprecationWarning: count is deprecated. Use Collection.count_documents instead.\n",
      "  from ipykernel import kernelapp as app\n",
      "/home/tbnsilveira/anaconda3/envs/analytics3/lib/python3.6/site-packages/ipykernel/__main__.py:3: DeprecationWarning: count is deprecated. Use Collection.count_documents instead.\n",
      "  app.launch_new_instance()\n",
      "/home/tbnsilveira/anaconda3/envs/analytics3/lib/python3.6/site-packages/ipykernel/__main__.py:4: DeprecationWarning: count is deprecated. Use Collection.count_documents instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database overview:\n",
      "Documents: 425642\n",
      "Nodes: 380322\n",
      "Ways: 45320\n",
      "Users: 188\n"
     ]
    }
   ],
   "source": [
    "data_information()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------\n",
    "### Do the database contains all the 46 oficially current cities of the Missões region?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We already know, from the audit and cleaning process, that the collected region has  **only 15 cities** (take a look at the \"expected cities\" in the audit section). This is due to the small portion of data selected to export from OSM, which does not mean the data for the other cities are not available.  \n",
    "For learning purpose, let's suppose it wasn't me who audited and cleaned this dataset, i.e. I just had access to this MongoDB collection. If it was the case I would run the following code in order tho find which cities are in the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities = db.aggregate([\n",
    "    {'$match':{'address.city':{'$exists':1}}},\n",
    "    {'$group':{'_id':'$address.city','count':{'$sum':1}}},\n",
    "    {'$sort':{'count':-1}}\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'_id': 'ijuí', 'count': 19},\n",
       " {'_id': 'cerro largo', 'count': 19},\n",
       " {'_id': 'panambi', 'count': 14},\n",
       " {'_id': 'santa rosa', 'count': 12},\n",
       " {'_id': 'condor', 'count': 6},\n",
       " {'_id': 'eugênio de castro', 'count': 6},\n",
       " {'_id': 'vila sírio', 'count': 5},\n",
       " {'_id': 'três de maio', 'count': 5},\n",
       " {'_id': 'santo ângelo', 'count': 4},\n",
       " {'_id': 'são josé do mauá', 'count': 3},\n",
       " {'_id': 'santo cristo', 'count': 2},\n",
       " {'_id': 'são miguel das missões', 'count': 1},\n",
       " {'_id': 'santo augusto', 'count': 1},\n",
       " {'_id': 'horizontina', 'count': 1},\n",
       " {'_id': 'cruz alta', 'count': 1}]"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(cities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------\n",
    "### What are the amenities and cuisines registered for this region?\n",
    "The Missões region is known as a historical and touristic place. The Jesuit Missions of the Guaranis, and specifically the ruins of São Miguel, are considered a world heritage by UNESCO since 1983 [6]. In this way, and knowing that amenities and cuisines are closely related to touristic regions, it would be interesting to explore how this services are operating in this region -- or at least, how this information is being inputed in the OpenStreetMap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_amenities():\n",
    "    result = db.aggregate([\n",
    "        {\"$match\":{\"amenity\":{\"$exists\":1},\"type\":\"node\"}},\n",
    "        {\"$group\":{\"_id\":\"$amenity\",\"count\":{\"$sum\":1}}},\n",
    "        {\"$sort\":{\"count\":-1}}])\n",
    "    return list(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'_id': 'place_of_worship', 'count': 90},\n",
       " {'_id': 'school', 'count': 63},\n",
       " {'_id': 'fuel', 'count': 62},\n",
       " {'_id': 'townhall', 'count': 23},\n",
       " {'_id': 'bank', 'count': 22},\n",
       " {'_id': 'police', 'count': 22},\n",
       " {'_id': 'restaurant', 'count': 20},\n",
       " {'_id': 'hospital', 'count': 19},\n",
       " {'_id': 'bus_station', 'count': 17},\n",
       " {'_id': 'parking', 'count': 15},\n",
       " {'_id': 'clinic', 'count': 10},\n",
       " {'_id': 'bar', 'count': 10},\n",
       " {'_id': 'ferry_terminal', 'count': 10},\n",
       " {'_id': 'pharmacy', 'count': 7},\n",
       " {'_id': 'post_office', 'count': 6},\n",
       " {'_id': 'college', 'count': 5},\n",
       " {'_id': 'fast_food', 'count': 5},\n",
       " {'_id': 'ice_cream', 'count': 4},\n",
       " {'_id': 'pub', 'count': 4},\n",
       " {'_id': 'telephone', 'count': 4},\n",
       " {'_id': 'arts_centre', 'count': 4},\n",
       " {'_id': 'taxi', 'count': 4},\n",
       " {'_id': 'courthouse', 'count': 4},\n",
       " {'_id': 'car_repair', 'count': 3},\n",
       " {'_id': 'community_centre', 'count': 3},\n",
       " {'_id': 'university', 'count': 2},\n",
       " {'_id': 'bbq', 'count': 2},\n",
       " {'_id': 'charging_station', 'count': 2},\n",
       " {'_id': 'marketplace', 'count': 2},\n",
       " {'_id': 'kindergarten', 'count': 2},\n",
       " {'_id': 'car_pooling', 'count': 1},\n",
       " {'_id': 'cafe', 'count': 1},\n",
       " {'_id': 'nightclub', 'count': 1},\n",
       " {'_id': 'childcare', 'count': 1},\n",
       " {'_id': 'hunting_stand', 'count': 1},\n",
       " {'_id': 'library', 'count': 1},\n",
       " {'_id': 'post_box', 'count': 1},\n",
       " {'_id': 'swimming_pool', 'count': 1},\n",
       " {'_id': 'fire_station', 'count': 1},\n",
       " {'_id': 'studio', 'count': 1}]"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_amenities()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_amenities_byCity():\n",
    "    result = db.aggregate([\n",
    "        {'$group': {'_id': '$address.city',\n",
    "                    'amenities': {\n",
    "                        '$addToSet': '$amenity'},\n",
    "                    'cuisine': {\n",
    "                        '$addToSet': '$cuisine'}\n",
    "                    }}])\n",
    "    return list(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And how are these amenities and cuisines distributed among the cities?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>amenities</th>\n",
       "      <th>cuisine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>são miguel das missões</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>são josé do mauá</td>\n",
       "      <td>[community_centre, fuel]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>horizontina</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cerro largo</td>\n",
       "      <td>[place_of_worship, restaurant, bank, universit...</td>\n",
       "      <td>[regional]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cruz alta</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ijuí</td>\n",
       "      <td>[bank, library, university, arts_centre, polic...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>None</td>\n",
       "      <td>[food_court, toilets, swimming_pool, courthous...</td>\n",
       "      <td>[steak_house, fine_dining, italian, pizza, bur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>vila sírio</td>\n",
       "      <td>[fuel, community_centre]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>santa rosa</td>\n",
       "      <td>[college, school, townhall, place_of_worship]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>panambi</td>\n",
       "      <td>[pharmacy, fuel, restaurant, college]</td>\n",
       "      <td>[Churrascaria, pizza]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>santo ângelo</td>\n",
       "      <td>[college]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>santo cristo</td>\n",
       "      <td>[hospital, place_of_worship]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>condor</td>\n",
       "      <td>[fuel, hospital]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>três de maio</td>\n",
       "      <td>[clinic, place_of_worship, school]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>eugênio de castro</td>\n",
       "      <td>[community_centre, school, clinic, place_of_wo...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>santo augusto</td>\n",
       "      <td>[college]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       _id                                          amenities  \\\n",
       "0   são miguel das missões                                                 []   \n",
       "1         são josé do mauá                           [community_centre, fuel]   \n",
       "2              horizontina                                                 []   \n",
       "3              cerro largo  [place_of_worship, restaurant, bank, universit...   \n",
       "4                cruz alta                                                 []   \n",
       "5                     ijuí  [bank, library, university, arts_centre, polic...   \n",
       "6                     None  [food_court, toilets, swimming_pool, courthous...   \n",
       "7               vila sírio                           [fuel, community_centre]   \n",
       "8               santa rosa      [college, school, townhall, place_of_worship]   \n",
       "9                  panambi              [pharmacy, fuel, restaurant, college]   \n",
       "10            santo ângelo                                          [college]   \n",
       "11            santo cristo                       [hospital, place_of_worship]   \n",
       "12                  condor                                   [fuel, hospital]   \n",
       "13            três de maio                 [clinic, place_of_worship, school]   \n",
       "14       eugênio de castro  [community_centre, school, clinic, place_of_wo...   \n",
       "15           santo augusto                                          [college]   \n",
       "\n",
       "                                              cuisine  \n",
       "0                                                  []  \n",
       "1                                                  []  \n",
       "2                                                  []  \n",
       "3                                          [regional]  \n",
       "4                                                  []  \n",
       "5                                                  []  \n",
       "6   [steak_house, fine_dining, italian, pizza, bur...  \n",
       "7                                                  []  \n",
       "8                                                  []  \n",
       "9                               [Churrascaria, pizza]  \n",
       "10                                                 []  \n",
       "11                                                 []  \n",
       "12                                                 []  \n",
       "13                                                 []  \n",
       "14                                                 []  \n",
       "15                                                 []  "
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.DataFrame(find_amenities_byCity())\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------\n",
    "### Additional suggestions\n",
    "Besides there are reach information available in OpenStreetMap database, being one that knows that region pretty well I could say there are so many information that should be added to this awesome open project. In this way, I will add up the following suggestions:  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (1) Enrich OSM with open data from oficial sources:  \n",
    "Brazil is a country with a relatively high rate of open data. The IBGE - Brazilian National Institute for Geography and Statistics provides open information for all that region, including service providers registers, which can be found in www.ibge.gov.br. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (2) Improve the available information in order to promote tourism in the region:\n",
    "There are some domestic airports in the region and an international one. However, these amenities are not foreseen in the OSM amenity set of keys. That's the same case for hotels. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (3) Improving data quality:  \n",
    "As anounced in the OSM Wiki [7], the 'yes' tag should be verified in order to be tagged with another value. Also, during the data exploration I found some amenities without address information, which could be added to it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------\n",
    "## Drawing some conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Despite the tourist and historical appeal of the place, there are a few scarce facilities in the region. There is no record of even an airport or bus station that serves the region.\n",
    "Initially, I attribute the fact to perhaps a small number of employees. However, the data show 188 employees in the region -- a relatively satisfactory number.  \n",
    "\n",
    "This analysis shows the opportunity to foster community participation in the data collection of this region, as well as opens up the opportunity for further investigation into these facts.\n",
    "\n",
    "From a technical point of view, this simple project allows the consolidation of the data wrangling concepts, including both the theoretical and practical approaches that involve the processes of data collection, auditing, cleaning and exporting -- fundamental steps in the work of any data scientist."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------\n",
    "## References\n",
    "[1] https://en.wikipedia.org/wiki/Miss%C3%B5es  \n",
    "[2] https://en.wikipedia.org/wiki/Spanish_missions_in_South_America  \n",
    "[3] https://jasonicarter.github.io/openstreetmap-data-wrangling-mongodb/  \n",
    "[4] https://eberlitz.github.io/2015/09/18/data-wrangle-openstreetmaps-data/  \n",
    "[5] https://wiki.openstreetmap.org/wiki/Key:addr  \n",
    "[6] http://www.unesco.org/new/en/brasilia/culture/world-heritage/list-of-world-heritage-in-brazil/jesuit-missions-of-the-guaranis/  \n",
    "[7] https://wiki.openstreetmap.org/wiki/Key:amenity#Tags_that_need_improvement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:analytics3]",
   "language": "python",
   "name": "conda-env-analytics3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
