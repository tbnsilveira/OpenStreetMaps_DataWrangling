{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data wrangling on OpenStreetMaps data\n",
    "In this project -- which is part of the Udacity Data Analysis Nanodegree -- I will apply some data munging techniques, such as assessing the quality of the data for validity, accuracy, completeness, consistency and uniformity, to clean an specific area from OpenStreetMap data. After it, in order to try database manipulation in Python, I will load the cleaned data to a MongoDB collection (installed locally in my machine) and apply some simple statistics on it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choosing an OpenStreetRegion: Missões!\n",
    "My region of interest in this project is Santo Ângelo, a countryside small city in the southest estate of Brazil which were my birthplace. However, since there's few data for this city and, for this project, I'm supposed to deal with databases larger than 50MB, I will consider all the neighboring cities, which in turn constitute the \"Missões\" region [1] and represent an important chapter in the South American history, since the first settlements were founded during the Spanish colonial missions [2].  \n",
    "\n",
    "Although today there are 46 municipalities composing this region, in the early eighteenth century there were only 7 villages, nowadays known in Portuguese as the \"Sete Povos das Missões\":\n",
    "- São Miguel das Missões  \n",
    "- Santo Ângelo  \n",
    "- São Borja  \n",
    "- São Nicolau  \n",
    "- São Luiz Gonzaga  \n",
    "- São Lourenço  \n",
    "- Entre-Ijuís (where remains the ruins of the town of São João Batista)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some basic statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.cElementTree as ET\n",
    "from collections import defaultdict\n",
    "import pprint\n",
    "import re\n",
    "\n",
    "# Dataset file name:\n",
    "FILENAME = 'Missoes.osm'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#% Regular expression functions:\n",
    "def avalia_regex(dataset, regex, nsamples=True, returnList=False):\n",
    "    '''Função auxiliar para avaliar o resultado de uma dada expressão regular (regex) em um texto (string type). \n",
    "    Syntaxe: avalia_regex(dataset, regex, nsamples=True, returnList=False),\n",
    "        dataset = texto tipo string que será avaliado;\n",
    "        regex = expressão regular a ser encontrada;\n",
    "        nsamples = True, mostra todas as amostras encontradas e, em caso contrário, apenas as 3 primeiras, se houver. \n",
    "        returnList = false. Se veradeiro, retorna uma lista com as expressões encontradas.\n",
    "        \n",
    "    Exemplo de uso: avalia_regex(t03, '\\.{2,}\\s')'''\n",
    "    filtro = re.findall(regex, dataset)\n",
    "    count = len(filtro)\n",
    "    print('Foram encontrados {} matches para a expressão \"{}.\"'.format(count, regex))\n",
    "    if nsamples:\n",
    "        for item in filtro:\n",
    "            print(item, end=', ')\n",
    "    else:\n",
    "        if count > 2:\n",
    "            print('\\te.g.: {}, {}, {}.'.format(filtro[0], filtro[1], filtro[2]))\n",
    "        elif count > 0:\n",
    "            print('\\te.g.: {}.'.format(filtro[0]))\n",
    "    if returnList:\n",
    "        return filtro\n",
    "    else:\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def substitui_regex(dataset, regex, subst):\n",
    "    '''Função auxiliar para substituir a coincidência de uma dada expressão regular (regex) em um texto (string type). \n",
    "    Syntaxe: avalia_regex(dataset, regex, subst), onde dataset é o texto tipo string; regex é a expressão regular a ser encontrada; subst é a string a qual será substituída. A função retorna a nova string.'''\n",
    "    filtro = re.findall(regex, dataset)\n",
    "    count = len(filtro)\n",
    "    print('Foram encontrados {} matches para a expressão \"{}.\"'.format(count, regex))\n",
    "    newText = re.sub(regex, subst, dataset)\n",
    "    return newText"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting and reading the data:\n",
    "The data was obtained from ... \n",
    "\n",
    "After downloading the data, the first step I should do if I did not know the data model would be a simple \"less\" shell command to figure out what kind of data were in it. Since OpenStreetMaps provides us with a data model, which in turn tells us how the information is organized inside the database, we get to know that the information we are interested in are in keys called 'tag'. Just to check how many of them we will have to process on this data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bounds': 1,\n",
      " 'member': 15589,\n",
      " 'meta': 1,\n",
      " 'nd': 444388,\n",
      " 'node': 380322,\n",
      " 'note': 1,\n",
      " 'osm': 1,\n",
      " 'relation': 949,\n",
      " 'tag': 93511,\n",
      " 'way': 45320}\n"
     ]
    }
   ],
   "source": [
    "#%% Getting acquainted to the dataset\n",
    "def count_tags(filename):\n",
    "    tags = {}\n",
    "    for event, element in ET.iterparse(filename):\n",
    "        if element.tag not in tags:\n",
    "            tags[element.tag] = 1\n",
    "        else: \n",
    "            tags[element.tag] += 1\n",
    "    return tags\n",
    "\n",
    "tags = count_tags(FILENAME)\n",
    "pprint.pprint(tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 93.511 tags we'll be dealing with in the next steps. We can move forward to the next step: starting to audit our data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auditing data:  \n",
    "The auditing questions comes when we start exploring the data or, if it's the case we have a prior knowledge of the problem, we already have in mind some issues to investigate. Considering there are available on Internet some similar analysis on OpenStreetMap data [3,4]; and also considering my previous knowledge about this region, I intend to audit the following issues:  \n",
    "- Are the cities names correct?\n",
    "- Are the street names correct?\n",
    "- Are there abbreviations?\n",
    "- Are the postal codes consistent?  \n",
    "\n",
    "It must be said that here the data are being first explored iteratively. Besides it is recommended to have one script for each field that is being audited, the whole process will be done through this Jupyter notebook in order to give an overview of the cleaning process. At the end, the code will be transferred to a standalone Python script (.py), in order to facilitate its automation when converting, cleaning and exporting data to a MongoDB collection, for example. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Are the cities names correct?\n",
    "In order to answer this question, I need first to know where this information is in the OpenStreetMaps (OSM) data model, which can be found in [5]. Consulting the documentation we get to know we are looking for the *addr:city* key. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 18 distinct cities in the dataset.\n",
      "['santa rosa', 'condor', 'ijuí', 'panambi', 'santo ângelo', 'três de maio', 'panambi - rs', 'santo cristo', 'eugênio de castro', 'santo augusto', 'santo angelo', 'cruz alta', 'vila sírio', 'cerro largo', 'são josé do mauá', 'são miguel das missões', 'horizontina', 'ijui']\n"
     ]
    }
   ],
   "source": [
    "#%% Finding the cities in the dataset\n",
    "def list_cities(filename):\n",
    "    cities = []\n",
    "    for _, elem in ET.iterparse(filename):\n",
    "        if elem.tag == 'tag':\n",
    "            k = elem.attrib['k']\n",
    "            v = elem.attrib['v'].lower()  #Lowering the uppercase text\n",
    "            if k == 'addr:city':\n",
    "                if v not in cities:\n",
    "                    cities.append(v)\n",
    "    print('There are {0} distinct cities in the dataset.'.format(len(cities)))\n",
    "    return cities\n",
    "\n",
    "cities = list_cities(FILENAME)\n",
    "print(cities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (1) Same cities are recorded with distinct names due to hyphenization or accentuation\n",
    "Even though I choose to use lowercase text, there are cities whose names are written with accentuation or hyphenized with the State abbreviation. A possible way to fix it is mapping the correct name to each case:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Cleaning the cities names:\n",
    "expected_cities = ['santa rosa', 'condor', 'ijuí', 'panambi', 'santo ângelo', 'três de maio',\n",
    "            'santo cristo', 'eugênio de castro', 'santo augusto', 'cruz alta', 'vila sírio', \n",
    "            'cerro largo', 'são josé do mauá', 'são miguel das missões', 'horizontina']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def audit_cities(expected_cities, filename):\n",
    "    weird = []\n",
    "    for _, elem in ET.iterparse(filename):\n",
    "        if elem.tag == 'tag':\n",
    "            k = elem.attrib['k']\n",
    "            v = elem.attrib['v'].lower()  #Lowering the uppercase text\n",
    "            if k == 'addr:city':\n",
    "                if v not in expected_cities:\n",
    "                    weird.append(v)\n",
    "    weird = set(weird)\n",
    "    print('There are {0} not expected cities in the dataset.'.format(len(weird)))\n",
    "    return weird"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 3 not expected cities in the dataset.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'ijui', 'panambi - rs', 'santo angelo'}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audit_cities(expected_cities, FILENAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After running the whole block of code, I could define the mapping:\n",
    "mapping_cities = {'ijui': 'ijuí',\n",
    "                  'santo angelo': 'santo ângelo',\n",
    "                  'panambi - rs': 'panambi'\n",
    "                 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "## When exporting data, the cities names must be corrected.\n",
    "def update_city(name, mapping):\n",
    "    for key in mapping:\n",
    "        if key in name:\n",
    "            return name.replace(key, mapping[key])\n",
    "    return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Are the street names correct? Are there any abbreviation?\n",
    "We will now iterate over all the registers to find wrong street names or abbreviations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "expected = [\"Rua\", \"Avenida\", \"Praça\", \"Via\", \"Estrada\", \"Travessa\", \"Linha\", \"Alameda\", \"Largo\", \"Parque\", \"Rodovia\"]\n",
    "\n",
    "### IMPORTANT: Brazilian street types are in the beginning of the phrase:\n",
    "street_type_re = re.compile(r'^\\b\\S+\\.?', re.IGNORECASE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def audit_street_type(street_types, street_name):\n",
    "    m = street_type_re.search(street_name)\n",
    "    if m:\n",
    "        street_type = m.group()\n",
    "        if street_type not in expected:\n",
    "            street_types[street_type].add(street_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_street_name(elem):\n",
    "    return (elem.attrib['k'] == \"addr:street\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def audit(osmfile):\n",
    "    osm_file = open(osmfile, \"r\")\n",
    "    street_types = defaultdict(set)\n",
    "    for event, elem in ET.iterparse(osm_file, events=(\"start\",)):\n",
    "        if elem.tag == \"node\" or elem.tag == \"way\":\n",
    "            for tag in elem.iter(\"tag\"):\n",
    "                if is_street_name(tag):\n",
    "                    audit_street_type(street_types, tag.attrib['v'])\n",
    "\n",
    "    return street_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    st_types = audit(FILENAME)\n",
    "    pprint.pprint(dict(st_types))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'14': {'14 de Julho'},\n",
      " '15': {'15 de Novembro'},\n",
      " 'Av.': {'Av. Santa Bárbara', 'Av. Gustav Kuhlmann'},\n",
      " 'BR': {'BR 285'},\n",
      " 'BR-285': {'BR-285'},\n",
      " 'BR-392': {'BR-392'},\n",
      " 'BR158': {'BR158'},\n",
      " 'Dom': {'Dom Pedro II'},\n",
      " 'ERS-342': {'ERS-342'},\n",
      " 'Getúlio': {'Getúlio Vargas'},\n",
      " 'Padre': {'Padre Afonso Rodrigues'},\n",
      " 'Paulo': {'Paulo Klemann'},\n",
      " 'RS': {'RS 218'},\n",
      " 'Santa': {'Santa Lucia'}}\n"
     ]
    }
   ],
   "source": [
    "test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the 'weirdos' found above, I will now write some mapping to clean the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After running the whole block of code, I could define the mapping:\n",
    "mapping = {'Av.': 'Avenida',\n",
    "           'BR ': 'BR-',\n",
    "           'BR158': 'BR-158',\n",
    "           'ERS-': 'RS-',\n",
    "           'RS ': 'RS-'\n",
    "          }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_name(name, mapping):\n",
    "    for key in mapping:\n",
    "        if key in name:\n",
    "            return name.replace(key, mapping[key])\n",
    "    return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    st_types = audit(FILENAME)\n",
    "    pprint.pprint(dict(st_types))\n",
    "\n",
    "    for st_type, ways in st_types.items():\n",
    "        for name in ways:\n",
    "            better_name = update_name(name, mapping)\n",
    "            print(name, \"=>\", better_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'14': {'14 de Julho'},\n",
      " '15': {'15 de Novembro'},\n",
      " 'Av.': {'Av. Santa Bárbara', 'Av. Gustav Kuhlmann'},\n",
      " 'BR': {'BR 285'},\n",
      " 'BR-285': {'BR-285'},\n",
      " 'BR-392': {'BR-392'},\n",
      " 'BR158': {'BR158'},\n",
      " 'Dom': {'Dom Pedro II'},\n",
      " 'ERS-342': {'ERS-342'},\n",
      " 'Getúlio': {'Getúlio Vargas'},\n",
      " 'Padre': {'Padre Afonso Rodrigues'},\n",
      " 'Paulo': {'Paulo Klemann'},\n",
      " 'RS': {'RS 218'},\n",
      " 'Santa': {'Santa Lucia'}}\n",
      "Getúlio Vargas => Getúlio Vargas\n",
      "BR-285 => BR-285\n",
      "Av. Santa Bárbara => Avenida Santa Bárbara\n",
      "Av. Gustav Kuhlmann => Avenida Gustav Kuhlmann\n",
      "BR 285 => BR-285\n",
      "RS 218 => RS-218\n",
      "15 de Novembro => 15 de Novembro\n",
      "14 de Julho => 14 de Julho\n",
      "BR-392 => BR-392\n",
      "ERS-342 => RS-342\n",
      "Padre Afonso Rodrigues => Padre Afonso Rodrigues\n",
      "Dom Pedro II => Dom Pedro II\n",
      "BR158 => BR-158\n",
      "Santa Lucia => Santa Lucia\n",
      "Paulo Klemann => Paulo Klemann\n"
     ]
    }
   ],
   "source": [
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "[1] https://en.wikipedia.org/wiki/Miss%C3%B5es  \n",
    "[2] https://en.wikipedia.org/wiki/Spanish_missions_in_South_America  \n",
    "[3] https://jasonicarter.github.io/openstreetmap-data-wrangling-mongodb/  \n",
    "[4] https://eberlitz.github.io/2015/09/18/data-wrangle-openstreetmaps-data/  \n",
    "[5] https://wiki.openstreetmap.org/wiki/Key:addr  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BACKUP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A. Application issues:   \n",
    "- Do the dataset contains more than the 46 current cities of the Missões region?\n",
    "- Do I have information from the 6 cities evolved form the ancient villages?\n",
    "\n",
    "B. Data issues:  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:analytics3]",
   "language": "python",
   "name": "conda-env-analytics3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
